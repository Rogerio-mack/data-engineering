{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdAtkGetVl79KlTAQ+tvGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rogerio-mack/data-engineering/blob/main/Aula_kafka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/mack_logo.png?raw=true\" height=\"70\" align=\"right\"/></a>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ifRIxMqtyJGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/Kafka1.png?raw=true\" height=\"250\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "-q7Ye_WPLled"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entendendo o Streaming de Transações com Apache Kafka\n",
        "\n",
        "## Definindo um fluxo de dados\n",
        "\n",
        "Um fluxo de dados é caracterizado por três características principais:\n",
        "\n",
        "* **Infinito**. Não há um início ou fim claramente definido para o conjunto de dados.\n",
        "\n",
        "* **Chegada esporádica**. Os dados podem chegar em grandes volumes em milissegundos ou em quantidades muito pequenas ao longo de horas ou dias.\n",
        "\n",
        "* **Tamanhos variados**. Os registros podem variar de kilobytes a gigabytes.\n",
        "Os fluxos de dados são diferentes dos dados em lote tradicionais, pois não são agrupados ou processados em unidades específicas.\n",
        "\n"
      ],
      "metadata": {
        "id": "zsfe4SLbS8QV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Captura de Dados de Mudança (CDC)\n",
        "\n",
        "Os dados transacionais são frequentemente gerados a partir de mudanças em bancos de dados, utilizando processos de **Captura de Dados de Mudança (CDC)**. O CDC permite a captura de alterações em tempo real, o que é essencial para a replicação e processamento rápidos. Isso é especialmente importante em cenários que exigem análises em tempo real, como transações online ou dados de redes sociais.\n",
        "\n"
      ],
      "metadata": {
        "id": "YX_HgPm0T3QY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oportunidades com streaming de dados transacionais\n",
        "\n",
        "O streaming de dados transacionais oferece várias oportunidades, como:\n",
        "\n",
        "* **Processamento em tempo real**. Permite a análise contínua e a resposta a eventos à medida que ocorrem.\n",
        "\n",
        "* **Redução do impacto em cargas de trabalho de produção**. Métodos de CDC não intrusivos minimizam a interferência nas operações do banco de dados.\n",
        "\n",
        "* **Entrega automatizada e de baixa latência**. O uso do Kafka facilita a entrega rápida e persistente de transações para múltiplos destinos."
      ],
      "metadata": {
        "id": "_RQlZoYqT5IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/Kafka2.png?raw=true\" height=\"350\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "lgzvjk2BewyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka3.png?raw=true\" height=\"450\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "1CVrAG02e37o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka4.png?raw=true\" height=\"306\" align=\"left\"/></a>\n",
        "\n",
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka5.png?raw=true\" height=\"170\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "zwsAaT_te-0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura do Kafka\n",
        "\n",
        "A arquitetura do Apache Kafka tem como principais componentes:\n",
        "\n",
        "* **Producers**. Aplicações que publicam dados em tópicos do Kafka.\n",
        "\n",
        "* **Tópicos**. Estruturas que armazenam fluxos de dados, semelhantes a logs de transações em bancos de dados. Os dados são organizados em partições, permitindo que múltiplos consumidores leiam dados simultaneamente.\n",
        "\n",
        ">> Um tópico é uma categoria ou um nome de canal onde os registros (ou mensagens) são publicados. **É a unidade organizacional básica no Kafka**, onde os dados são armazenados e consumidos. **Cada tópico é um log imutável e ordenado de registros, que é append-only**, ou seja, novos registros são adicionados ao final do log. Os registros dentro de um tópico são identificados por um offset, que é um número sequencial que indica a posição do registro no log. Nomeação: Os tópicos são geralmente nomeados de acordo com o tipo de dados que contêm, como `user-activity`, `orders`, ou `sensor-data`.\n",
        "\n",
        ">> Cada tópico pode ser dividido em várias **partições**. Uma **partição** é uma subdivisão do tópico que permite que os dados sejam distribuídos e processados em paralelo. As partições são criadas quando um tópico é definido. O número de partições pode ser especificado no momento da criação do tópico e pode ser ajustado posteriormente, mas isso pode ter implicações na ordem dos dados. As partições são distribuídas entre os brokers do cluster Kafka o que permite que múltiplos brokers armazenem partes do mesmo tópico, aumentando a escalabilidade e a resiliência do sistema. **Cada partição é lida e escrita de forma independente, permitindo que múltiplos consumidores leiam de diferentes partições ao mesmo tempo, o que melhora a taxa de transferência e reduz a latência, mas os registros dentro de uma partição são garantidos para serem lidos na ordem em que foram escritos. No entanto, não há garantia de ordem entre diferentes partições de um mesmo tópico.**\n",
        "\n",
        "* **Consumers**. Aplicações que leem dados dos tópicos. Eles podem processar dados em tempo real ou em lotes, dependendo das necessidades do negócio.\n",
        "\n",
        "* **Clusters**: Conjuntos de servidores que trabalham juntos para garantir a alta disponibilidade e a escalabilidade do Kafka.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i24imm-fg9ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka7.png?raw=true\" height=\"300\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "HHlUkbqTfxG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Brokers**. Os brokers são os servidores que compõem um cluster Kafka. Cada broker é **responsável por armazenar dados e atender às solicitações de leitura e gravação de produtores e consumidores. Eles gerenciam a persistência dos dados em tópicos e partições.** Eles garantem que os dados sejam replicados entre diferentes brokers para alta disponibilidade e tolerância a falhas. Quando um produtor envia dados, ele se conecta a um broker, que então armazena os dados no tópico apropriado.\n",
        "\n"
      ],
      "metadata": {
        "id": "mwibGUBBh4Oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka6.png?raw=true\" height=\"350\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "3Vz6GHUbftZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Zookeeper**. O Zookeeper é um serviço de coordenação que ajuda a gerenciar e manter a configuração do cluster Kafka. É responsável por várias tarefas que incluem:\n",
        "\n",
        "> * Gerenciamento de metadados: O Zookeeper mantém informações sobre os brokers disponíveis, tópicos, partições e suas réplicas.\n",
        "\n",
        "> * Coordenação de líderes: O Zookeeper ajuda a eleger um broker líder para cada partição, que é o único responsável por gerenciar as operações de leitura e gravação para essa partição.\n",
        "\n",
        "> * Monitoramento de estado: O Zookeeper monitora a saúde dos brokers e pode detectar falhas, permitindo que o Kafka reconfigure automaticamente o cluster."
      ],
      "metadata": {
        "id": "h3U7EYfriNQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Serialização**. No Apache Kafka, a serialização dos dados refere-se ao processo de converter objetos em um formato de byte que pode ser transmitido e armazenado. O formato da serialização pode variar dependendo das necessidades da aplicação e dos tipos de dados.\n",
        "\n",
        "> 1. String Serialization:\n",
        "Comum para dados simples, como mensagens de texto.\n",
        "\n",
        "> 2. JSON Serialization: Útil para dados estruturados, pois o JSON é legível e amplamente utilizado em APIs e serviços web.\n",
        "\n",
        "> 3. Avro Serialization: O Avro é um sistema de serialização de dados que fornece um formato compacto e um esquema para descrever a estrutura dos dados. Para aplicações que requerem evolução de esquema, pois permite que os dados sejam lidos mesmo que o esquema tenha mudado.\n",
        "\n",
        "> 4. Protocol Buffers (Protobuf): esenvolvido pelo Google, é usado em sistemas que requerem comunicação rápida entre serviços, especialmente em ambientes de microserviços.\n",
        "\n",
        "> 5. Outros"
      ],
      "metadata": {
        "id": "JRSKb-iVi6dK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Conectores**. O Kafka Connect utiliza conectores, que são componentes que ajudam a transferir dados de fontes externas (como bancos de dados) para tópicos do Kafka e vice-versa. Esses conectores podem ser configurados para realizar operações de leitura e gravação de dados de forma incremental, em tempo quase real ou em lotes."
      ],
      "metadata": {
        "id": "yyEsjkFWl7g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingestão de dados\n",
        "\n",
        "A ingestão de dados com o Kafka pode ser feita por meio de aplicações que utilizam o Kafka Connect ou através de técnicas de CDC.\n",
        "\n",
        "**Kafka Connect**, é uma ferramenta que facilita a integração de dados entre o Apache Kafka e outros sistemas. A API Kafka Connect permite que você mova dados para dentro e para fora do Kafka de forma escalável e reutilizável."
      ],
      "metadata": {
        "id": "POTUYPpzntAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usando Change Data Capture (CDC) para Integrar Dados\n",
        "\n",
        "**CDC: O Change Data Capture (CDC)** é uma técnica que permite rastrear e capturar mudanças em conjuntos de dados de origem. Ele é utilizado para replicar alterações em bancos de dados ou outras fontes de dados com pouco ou nenhum impacto nas fontes originais.\n",
        "\n",
        "Métodos comuns de CDC, captura de dados:\n",
        "\n",
        "* **Triggers**. Utilizam gatilhos em bancos de dados para registrar alterações em uma tabela separada, que é então replicada.\n",
        "\n",
        "* **Query-based**. Um mecanismo de CDC consulta o banco de dados em busca de novas alterações, usando timestamps ou números de versão.\n",
        "\n",
        "* **Log-based**. O CDC analisa logs de transações para identificar e replicar mudanças.\n",
        "\n",
        "Os dados transacionais capturados via CDC são armazenados em tópicos do Kafka, permitindo que sejam consumidos por diferentes aplicações e serviços. **Os registros armazenados no Kafka podem ser mantidos por longos períodos, permitindo que sejam reproduzidos ou consumidos em velocidades variadas** e podem podem ser utilizados para diversas finalidades, como análises em tempo real, integração com microserviços e processamento de eventos."
      ],
      "metadata": {
        "id": "C4e4nFKQmf5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka9.png?raw=true\" height=\"450\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "fNd0Lzhvf_Xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Rogerio-mack/data-engineering/blob/main/figs/kafka10.png?raw=true\" height=\"350\" align=\"left\"/></a>"
      ],
      "metadata": {
        "id": "tEtrBuusgC-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplos Práticos de Uso do Kafka para Ingestão de Dados\n",
        "\n",
        "Embora um uso comum seja o CDC (Change Data Capture), existem outros cenários em que o Kafka Connect é bastante útil.\n",
        "\n",
        "## **Integração com Sistemas IoT Usando Kafka Connect**\n",
        "\n",
        "Imagine um sistema de **gerenciamento de dispositivos IoT**, como sensores de temperatura, umidade, etc. Esses sensores podem enviar dados em tempo real para uma plataforma de gerenciamento de dados. Um conector específico do Kafka Connect pode ser utilizado para integrar esses dados com sistemas externos, como uma solução de armazenamento em nuvem (ex.: Amazon S3).\n",
        "\n",
        "**Fluxo:**\n",
        "1. **Dispositivos IoT** enviam dados de sensores para um broker MQTT (protocolo popular para IoT).\n",
        "2. O **Kafka Connect MQTT Source Connector** é configurado para consumir dados do broker MQTT e enviar esses dados para um tópico Kafka.\n",
        "3. O **Kafka Connect S3 Sink Connector** é configurado para mover os dados do Kafka para o Amazon S3, onde os dados podem ser analisados posteriormente.\n",
        "\n",
        "```bash\n",
        "# Configuração de um MQTT Source Connector\n",
        "{\n",
        "  \"name\": \"mqtt-source-connector\",\n",
        "  \"config\": {\n",
        "    \"connector.class\": \"io.confluent.connect.mqtt.MqttSourceConnector\",\n",
        "    \"mqtt.server.uri\": \"tcp://broker:1883\",\n",
        "    \"mqtt.topics\": \"sensor/temperature\",\n",
        "    \"kafka.topic\": \"iot-sensors\",\n",
        "    \"tasks.max\": \"1\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Configuração de um S3 Sink Connector\n",
        "{\n",
        "  \"name\": \"s3-sink-connector\",\n",
        "  \"config\": {\n",
        "    \"connector.class\": \"io.confluent.connect.s3.S3SinkConnector\",\n",
        "    \"s3.bucket.name\": \"iot-data\",\n",
        "    \"topics\": \"iot-sensors\",\n",
        "    \"format.class\": \"io.confluent.connect.s3.format.json.JsonFormat\",\n",
        "    \"partitioner.class\": \"io.confluent.connect.storage.partitioner.DefaultPartitioner\",\n",
        "    \"tasks.max\": \"1\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "A Kafka Connect integra o fluxo de dados IoT em tempo real com o armazenamento em nuvem, facilitando o processamento e a análise de grandes volumes de dados de sensores.\n",
        "\n",
        "## **Detecção de Fraudes em Transações Bancárias**\n",
        "\n",
        "O **Kafka Connect** pode ser configurado para se conectar a um banco de dados SQL ou NoSQL (MySQL, PostgreSQL, MongoDB) usando conectores predefinidos ou pode-se usar conectores CDC. O Kafka publica os dados de transações em tempo real para tópicos, onde os consumidores, como Algoritmos de aprendizado de máquina, identificam transações que têm maior risco de fraude. O uso do Kafka permite um fluxo contínuo e escalável de ingestão de dados, processando em tempo real e fornecendo detecção de fraudes mais rápida.\n",
        "\n",
        "## **Sincronização de Dados entre Aplicações Web e Móveis**\n",
        "\n",
        "Aplicativos móveis e web muitas vezes precisam garantir que as informações dos usuários (como perfis ou status de transações) estejam sempre atualizadas em tempo real. A técnica de **CDC** pode ser usada para capturar alterações em bancos de dados backend e enviá-las ao Kafka, que distribui essas atualizações para os consumidores. A sincronização de dados é feita entre várias plataformas sem a necessidade de consultas constantes ao banco de dados, economizando recursos e tempo de resposta.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7C4pkWqyqel_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kafka $\\times$ RabbitMQ\n",
        "\n",
        "Essa é uma questão comum, mas o **RabbitMQ** e o **Kafka**, embora muitas vezes possam ser intercambiáveis, eles **têm propósitos diferentes!**\n",
        "\n",
        "## **RabbitMQ**\n",
        "\n",
        "O **RabbitMQ** é um broker de mensagens **orientado a filas** (message-oriented middleware). Ele é projetado para transmitir e rotear mensagens entre produtores e consumidores em tempo real. A ideia central é que mensagens podem ser enfileiradas e consumidas por diferentes aplicações, com garantias de entrega como **at-least-once** e **exactly-once**. O RabbitMQ trabalha com **filas** (e não com tópicos) onde as mensagens são entregues a consumidores únicos (ponto a ponto).\n",
        "\n",
        ">> **Uma mensagem publicada em uma fila será consumida por um único consumidor**.\n",
        "\n",
        "O RabbitMQ é ideal para situações onde você precisa rotear mensagens entre serviços, controlar fluxos de trabalho assíncronos ou garantir que cada mensagem seja processada apenas uma vez.\n",
        "\n",
        "## **Kafka**\n",
        "\n",
        "Já o **Kafka** é um sistema de **streaming distribuído**, projetado para publicar, armazenar e processar fluxos contínuos de dados. Sua arquitetura não é baseada em filas, mas sim em **tópicos particionados**, onde\n",
        "\n",
        ">> **mensagens são armazenadas de forma imutável e podem ser consumidas por múltiplos consumidores de forma paralela**.\n",
        "\n",
        "O Kafka é otimizado para a transmissão contínua e processamento em **tempo real de grandes volumes de dados**. Ele também oferece **persistência e replay de mensagens**, algo que não é comumente encontrado em sistemas de mensageria pura.\n",
        "O Kafka é usado em cenários onde o volume de dados é muito grande ou onde há necessidade de processamento em tempo real, como análise de logs, monitoramento de eventos, ou streaming de dados de sensores.\n",
        "\n",
        "\n",
        "| Característica               | RabbitMQ                       | Kafka                        |\n",
        "|------------------------------|---------------------------------|------------------------------|\n",
        "| **Modelo de Mensagem**        | Fila (point-to-point)           | Tópico (pub/sub)              |\n",
        "| **Entrega de Mensagens**      | At-least-once, Exactly-once     | At-least-once, Exactly-once   |\n",
        "| **Persistência de Mensagens** | Opcional                       | Sempre (até retenção definida)|\n",
        "| **Processamento em Tempo Real** | Limitado                      | Otimizado para streaming      |\n",
        "| **Escalabilidade**            | Difícil com alta concorrência   | Altamente escalável           |\n",
        "| **Garantia de Ordem**         | Ordem em fila, não global       | Ordem por partição            |\n",
        "\n",
        "Como limitações, o RabbitMQ, tem escalabilidade limitada com grandes volumes de dados e para persistência de longo prazo, enquanto o Kafka tem muito maior complexidade na instalação e operação e latência maior para pequenas mensagens se comparado ao RabbitMQ.\n",
        "\n"
      ],
      "metadata": {
        "id": "7E8SoH_zucM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concorrentes do Kafka e Distribuições Comerciais\n",
        "\n",
        "## Concorrentes\n",
        "\n",
        "- **Amazon Kinesis**\n",
        "- **Azure Event Hubs**\n",
        "- **Google Pub/Sub** (mas é mais um \"Serviço de mensageria da Google Cloud\")\n",
        "  \n",
        "## Distribuições Comerciais\n",
        "\n",
        "- **Confluent Kafka**, fundada pelos criadores do Kafka, oferece uma distribuição comercial do Kafka com recursos adicionais como monitoramento, controle de acesso e interfaces de gestão mais amigáveis.\n",
        "\n",
        "- **Cloudera Kafka**\n",
        "\n",
        "- **AWS Managed Streaming for Apache Kafka (MSK)**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rj5DauTurBeS"
      }
    }
  ]
}